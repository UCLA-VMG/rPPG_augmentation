{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"rppg_aug.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"UgxgR-_1Gkui"},"source":["# Library"]},{"cell_type":"code","metadata":{"id":"RyHoC9eGj43j"},"source":["import os, os.path\n","\n","import json\n","import h5py\n","\n","import torch # Tested with PyTorch version 1.7.1\n","import torch.nn as nn\n","from torch.nn import init\n","from torch.utils.data import Dataset, DataLoader\n","import torch.optim as optim\n","\n","import numpy as np\n","import cv2\n","import random\n","\n","import matplotlib.pyplot as plt\n","from pathlib import Path"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Helper"],"metadata":{"id":"MTigujV7c_Ff"}},{"cell_type":"code","source":["def tensor2img(tensor, normalization=False):\n","  img = tensor.cpu().numpy().transpose((1, 2, 0))\n","  if normalization: # Normalize to [0, 1] for visualization \n","    img = (img - img.min()) / (img.max() - img.min())\n","  else: # Convert [-1, 1] to [0, 1]\n","    img = (img + 1) / 2\n","  return img\n","\n","def multiple_tensors_show(tensors, normalization_list):\n","  f, axarr = plt.subplots(1, len(tensors), figsize=(5 * len(tensors), 5))\n","  for i, tensor in enumerate(tensors):\n","    img = tensor2img(tensor, normalization=normalization_list[i])\n","    axarr[i].imshow(img)\n","  plt.show()"],"metadata":{"id":"Jmfd6R3Zc_MV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"P4Os9bD2I2F1"},"source":["# Dataloader"]},{"cell_type":"code","metadata":{"id":"ZiJXPPDGkgP6"},"source":["class DatasetUBFC(Dataset):\n","  \"\"\"\n","      Dataset class for training network.\n","  \"\"\"\n","\n","  def __init__(\n","      self, root_dir, root_dir_transfered, \n","      session_names, num_samples, \n","      seq_length, device, resize_shape\n","      ):\n","      \n","    self.resize_shape = resize_shape\n","    self.sessions = session_names\n","    self.seq_length = seq_length    \n","\n","    self.all_sessions = []\n","    self.length = num_samples\n","    self.ppg_der = {}\n","    self.frames = {}\n","    self.masks = {}\n","    self.frames_transfered = {}\n","    self.root_dir_transfered = root_dir_transfered\n","\n","    for session in self.sessions:\n","      db = h5py.File(os.path.join(root_dir, session + '.h5'), 'r')\n","      frames = db['dataset_1']\n","      target = db['ppg']\n","\n","      if self.root_dir_transfered:\n","        db_transfered = h5py.File(os.path.join(root_dir_transfered, session + '_af.h5'), 'r')\n","        frames_transfered = db_transfered['dataset_1']\n","        self.frames_transfered[session] = frames_transfered \n","      \n","      # Normalize PPG\n","      target = target - np.mean(target)\n","      target = target / np.std(target)\n","      \n","      self.frames[session] = frames\n","      self.ppg_der[session] = target\n","\n","      if self.root_dir_transfered:\n","        self.frames_transfered[session] = frames_transfered  \n","\n","  def __len__(self):\n","    return (self.length)\n","\n","  def __getitem__(self, idx):\n","\n","    # Pick a session\n","    session_num = np.random.randint(low=0, high=len(self.sessions))\n","        \n","    subject = self.sessions[session_num]\n","    frames = self.frames[subject]\n","\n","    cur_ppg_signal = self.ppg_der[subject]\n","    \n","    if self.root_dir_transfered:\n","      frames_transfered = self.frames_transfered[subject]\n","\n","    # Pick a random frame\n","    cur_frame_num = np.random.randint(\n","        low=0, high=len(frames_transfered) - self.seq_length # Can't pick the last frame.\n","        )\n","\n","    temp_next_frames_list = []\n","    temp_next_ppgs_list = []\n","\n","    if self.root_dir_transfered:\n","      temp_transfered_next_frames_list = []\n","\n","    # Following frames\n","    for j in range(self.seq_length):\n","      next_frame = frames[cur_frame_num + j]\n","      next_frame = cv2.resize(\n","          next_frame, self.resize_shape, \n","          interpolation=cv2.INTER_LINEAR\n","          )\n","      next_frame = torch.from_numpy(next_frame).permute(2, 0, 1).float()\n","      next_frame = next_frame / 127.5 - 1\n","\n","      if self.root_dir_transfered:\n","        transfered_next_frame = frames_transfered[cur_frame_num + j]\n","        transfered_next_frame = cv2.resize(\n","            transfered_next_frame, self.resize_shape, \n","            interpolation=cv2.INTER_LINEAR\n","            )\n","        transfered_next_frame = torch.from_numpy(transfered_next_frame).permute(2, 0, 1).float()\n","        transfered_next_frame = transfered_next_frame / 127.5 - 1\n","\n","      temp_next_frames_list.append(next_frame)\n","      if self.root_dir_transfered:\n","        temp_transfered_next_frames_list.append(transfered_next_frame)\n","      next_ppg_value = cur_ppg_signal[cur_frame_num + j]\n","      temp_next_ppgs_list.append(torch.from_numpy(\n","        np.array(next_ppg_value).astype('float32')\n","        ))\n","      \n","    data = {\n","      'next_frame': torch.stack(temp_next_frames_list),\n","      'next_ppg_value': torch.stack(temp_next_ppgs_list),\n","    }\n","    if self.root_dir_transfered:\n","      data['transfered_next_frame'] = torch.stack(temp_transfered_next_frames_list)\n","\n","    return data"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Generator"],"metadata":{"id":"z96NRsuBczt9"}},{"cell_type":"code","metadata":{"id":"WRdhuN4c45KR"},"source":["\"\"\"\n","The code is modified from https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix.\n","\"\"\"\n","\n","def init_weights(net, init_type='normal', init_gain=0.02):\n","    \"\"\"\n","    Initialize network weights.\n","    \"\"\"\n","    def init_func(m):  # define the initialization function\n","        classname = m.__class__.__name__\n","        if hasattr(m, 'weight') and (classname.find('Conv') != -1 or classname.find('Linear') != -1):\n","            if init_type == 'normal':\n","                init.normal_(m.weight.data, 0.0, init_gain)\n","            elif init_type == 'xavier':\n","                init.xavier_normal_(m.weight.data, gain=init_gain)\n","            elif init_type == 'kaiming':\n","                init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n","            elif init_type == 'orthogonal':\n","                init.orthogonal_(m.weight.data, gain=init_gain)\n","            else:\n","                raise NotImplementedError('initialization method [%s] is not implemented' % init_type)\n","            if hasattr(m, 'bias') and m.bias is not None:\n","                init.constant_(m.bias.data, 0.0)\n","        elif classname.find('BatchNorm2d') != -1:  # BatchNorm Layer's weight is not a matrix; only normal distribution applies.\n","            init.normal_(m.weight.data, 1.0, init_gain)\n","            init.constant_(m.bias.data, 0.0)\n","\n","    print('initialize network with %s' % init_type)\n","    net.apply(init_func)  # apply the initialization function <init_func>\n","\n","\n","def init_net(net, init_type='normal', init_gain=0.02, gpu_ids=[]):\n","    \"\"\"\n","    Initialize a network.\n","    \"\"\"\n","    if len(gpu_ids) > 0:\n","        assert(torch.cuda.is_available())\n","        net.to(gpu_ids[0])\n","        net = torch.nn.DataParallel(net, gpu_ids)  # multi-GPUs\n","    init_weights(net, init_type, init_gain=init_gain)\n","    return net"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pKfTBFVvmhzy"},"source":["class ResnetGenerator3d(nn.Module):\n","    \"\"\"\n","    Resnet-based generator that consists of Resnet blocks between a few downsampling/upsampling operations.\n","    \"\"\"\n","\n","    def __init__(self, input_nc, output_nc, ngf=64, norm_layer=nn.BatchNorm3d, use_dropout=False, n_blocks=6, padding_type='reflect'):\n","        \"\"\"\n","        Construct a Resnet-based generator\n","        \"\"\"\n","        assert(n_blocks >= 0)\n","        super(ResnetGenerator3d, self).__init__()\n","        if type(norm_layer) == functools.partial:\n","            use_bias = norm_layer.func == nn.InstanceNorm3d\n","        else:\n","            use_bias = norm_layer == nn.InstanceNorm3d\n","\n","        model = [nn.ReplicationPad3d(3),\n","                 nn.Conv3d(input_nc, ngf, kernel_size=7, padding=0, bias=use_bias),\n","                 norm_layer(ngf),\n","                 nn.ReLU()]\n","\n","        n_downsampling = 2\n","        for i in range(n_downsampling):  # add downsampling layers\n","            mult = 2 ** i\n","            model += [nn.Conv3d(ngf * mult, ngf * mult * 2, kernel_size=3, stride=2, padding=1, bias=use_bias),\n","                      norm_layer(ngf * mult * 2),\n","                      nn.ReLU()]\n","\n","        mult = 2 ** n_downsampling\n","        for i in range(n_blocks):       # add ResNet blocks\n","\n","            model += [ResnetBlock(ngf * mult, padding_type=padding_type, norm_layer=norm_layer, use_dropout=use_dropout, use_bias=use_bias)]\n","\n","        for i in range(n_downsampling):  # add upsampling layers\n","            mult = 2 ** (n_downsampling - i)\n","            model += [nn.ConvTranspose3d(ngf * mult, int(ngf * mult / 2),\n","                                         kernel_size=3, stride=2,\n","                                         padding=1, output_padding=1,\n","                                         bias=use_bias),\n","                      norm_layer(int(ngf * mult / 2)),\n","                      nn.ReLU()]\n","        model += [nn.ReplicationPad3d(3)]\n","        model += [nn.Conv3d(ngf, output_nc, kernel_size=7, padding=0)]\n","        model += [nn.Tanh()]\n","\n","        self.model = nn.Sequential(*model)\n","\n","    def forward(self, input):\n","        \"\"\"Standard forward\"\"\"\n","        return self.model(input)\n","\n","\n","class ResnetBlock(nn.Module):\n","    \"\"\"Define a Resnet block\"\"\"\n","\n","    def __init__(self, dim, padding_type, norm_layer, use_dropout, use_bias):\n","        \"\"\"\n","        Initialize the Resnet block\n","        \"\"\"\n","        super(ResnetBlock, self).__init__()\n","        self.conv_block = self.build_conv_block(dim, padding_type, norm_layer, use_dropout, use_bias)\n","\n","    def build_conv_block(self, dim, padding_type, norm_layer, use_dropout, use_bias):\n","        \"\"\"\n","        Construct a convolutional block.\n","        \"\"\"\n","        conv_block = []\n","        p = 0\n","        if padding_type == 'reflect':\n","            conv_block += [nn.ReplicationPad3d(1)]\n","        elif padding_type == 'replicate':\n","            conv_block += [nn.ReplicationPad3d(1)]\n","        elif padding_type == 'zero':\n","            p = 1\n","        else:\n","            raise NotImplementedError('padding [%s] is not implemented' % padding_type)\n","\n","        conv_block += [nn.Conv3d(dim, dim, kernel_size=3, padding=p, bias=use_bias), norm_layer(dim), nn.ReLU(True)]\n","        if use_dropout:\n","            conv_block += [nn.Dropout(0.5)]\n","\n","        p = 0\n","        if padding_type == 'reflect':\n","            conv_block += [nn.ReplicationPad3d(1)]\n","        elif padding_type == 'replicate':\n","            conv_block += [nn.ReplicationPad3d(1)]\n","        elif padding_type == 'zero':\n","            p = 1\n","        else:\n","            raise NotImplementedError('padding [%s] is not implemented' % padding_type)\n","        conv_block += [nn.Conv3d(dim, dim, kernel_size=3, padding=p, bias=use_bias), norm_layer(dim)]\n","\n","        return nn.Sequential(*conv_block)\n","\n","    def forward(self, x):\n","        \"\"\"Forward function (with skip connections)\"\"\"\n","        out = x + self.conv_block(x)  # add skip connections\n","        return out"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KfDDUDXqtjfj"},"source":["import functools\n","\n","def get_norm_layer3d(norm_type='instance'):\n","    \"\"\"\n","    Return a normalization layer\n","    \"\"\"\n","    if norm_type == 'batch':\n","        norm_layer = functools.partial(nn.BatchNorm3d, affine=True, track_running_stats=True)\n","    elif norm_type == 'instance':\n","        norm_layer = functools.partial(nn.InstanceNorm3d, affine=False, track_running_stats=False)\n","    else:\n","        raise NotImplementedError('normalization layer [%s] is not found' % norm_type)\n","    return norm_layer"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BzJ31V4_aTLO"},"source":["# PhysResNet (PRN)\n"]},{"cell_type":"code","metadata":{"id":"o5wRpdxRUuTA"},"source":["class RPPGNetResnet(nn.Module):\n","  def __init__(self, seq_length):\n","    super().__init__()\n","\n","    self.learned_shortcut1 = nn.Conv3d(3, 16, kernel_size=1, bias=False)\n","    self.layers1 = nn.Sequential(\n","        nn.Conv3d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1, bias=True),\n","        nn.BatchNorm3d(16),\n","        nn.ReLU(),\n","        nn.AvgPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0),\n","        nn.Conv3d(in_channels=16, out_channels=16, kernel_size=3, stride=1, padding=1, bias=True),\n","        nn.BatchNorm3d(16),\n","        nn.ReLU(),\n","        nn.AvgPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0)\n","    )\n","    self.pool1 = nn.AvgPool3d(kernel_size=(1, 4, 4), stride=(1, 4, 4), padding=0)\n","\n","    self.learned_shortcut2 = nn.Conv3d(16, 64, kernel_size=1, bias=False)\n","    self.layers2 = nn.Sequential(\n","        nn.Conv3d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1, bias=True),\n","        nn.BatchNorm3d(32),\n","        nn.ReLU(),\n","        nn.AvgPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0),\n","        nn.Conv3d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1, bias=True),\n","        nn.BatchNorm3d(64),\n","        nn.ReLU(),\n","        nn.AvgPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0)\n","    )\n","    self.pool2 = nn.AvgPool3d(kernel_size=(1, 4, 4), stride=(1, 4, 4), padding=0)\n","\n","    self.learned_shortcut3 = nn.Conv3d(64, 256, kernel_size=1, bias=False)\n","    self.layers3 = nn.Sequential(\n","        nn.Conv3d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1, bias=True),\n","        nn.BatchNorm3d(128),\n","        nn.ReLU(),\n","        nn.AvgPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=(0, 1, 1)),\n","        nn.Conv3d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1, bias=True),\n","        nn.BatchNorm3d(256),\n","        nn.ReLU()\n","    )\n","    \n","    self.pool3 = nn.AvgPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=(0, 1, 1))\n","\n","    self.pooling = nn.AdaptiveAvgPool3d((seq_length, 1, 1))\n","    self.final_conv = nn.Conv3d(in_channels=256, out_channels=1, kernel_size=1, stride=1, padding=0, bias=True)\n","    \n","  def forward(self, A):   \n","\n","    identity = A\n","    out = self.layers1(A)   \n","    out += self.learned_shortcut1(self.pool1(identity))\n","  \n","    identity = out \n","    out = self.layers2(out)\n","    out += self.learned_shortcut2(self.pool2(identity))\n","    \n","    identity = out\n","    out = self.layers3(out)\n","    out += self.learned_shortcut3(self.pool3(identity))\n","\n","    out = self.pooling(out)\n","    out = self.final_conv(out)\n","\n","    return out"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Loss"],"metadata":{"id":"4vpKm_ZtcxfK"}},{"cell_type":"code","metadata":{"id":"8n6hE-KSvrEr"},"source":["tr = torch\n","\n","class NegPeaLoss(nn.Module):\n","  def __init__(self):\n","    super(NegPeaLoss, self).__init__()\n","\n","  def forward(self, x, y):\n","    if len(x.size()) == 1:\n","      x = tr.unsqueeze(x, 0)\n","      y = tr.unsqueeze(y, 0)\n","    T = x.shape[1]\n","    p_coeff = tr.sub(T * tr.sum(tr.mul(x, y), 1), tr.mul(tr.sum(x, 1), tr.sum(y, 1)))\n","    norm = tr.sqrt((T * tr.sum(x ** 2, 1) - tr.sum(x, 1) ** 2) * (T * tr.sum(y ** 2, 1) - tr.sum(y, 1) ** 2))\n","    p_coeff = tr.div(p_coeff, norm)\n","    losses = tr.tensor(1.) - p_coeff\n","    totloss = tr.mean(losses)\n","    return totloss\n","\n","class ThresholdLoss(nn.Module):\n","  def __init__(self, threshold=0.1):\n","    super(ThresholdLoss, self).__init__()\n","    self.threshold = threshold\n","\n","  def forward(self, est, gt):\n","    l1_map = torch.abs(est - gt)\n","    return torch.mean(l1_map[l1_map > self.threshold])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"C53ZzIClFp4r"},"source":["# Training "]},{"cell_type":"code","metadata":{"id":"6qgpvFnFJwY6"},"source":["## Training parameters\n","params = {\n","    'batch_size': 2, # Batch size during training.\n","    'num_samples': 160, # Number of samples in each epoch\n","    'seq_length': 256, # Number of frames as the next frames\n","    'img_shape': (80, 80), # Spatial size of training images.\n","    'num_epochs': 601, # Number of training epochs.\n","    'lr': 0.0001, # Learning rate for optimizer 0.0003\n","    'lr_rppgnet': 0.0003,\n","    'display_tensor': 15, # Show images during training\n","    'val_epoch': 15, # Perform validation every K epochs\n","    'save_path': './model_checkpoint_folder', # Name for saving the model weights\n","    'save_name_generator': 'generator_checkpoint.pt',\n","    'save_name_rppgnet': 'rppgnet_checkpoint.pt',\n","    'rgb_loss_weight': 1.0,\n","    'rppgnet_loss_weight': 1.0, # Loss weight for rPPG loss\n","    'input_nc': 3,\n","    'output_nc': 3,\n","    'ngf': 64,\n","    'dropout': False,\n","    'norm': 'instance',\n","    'weight_decay': 0.0, # Regularization\n","    'beta1': 0.5, # Adam beta1\n","    'beta2': 0.999, # Adam beta2\n","    'init_type': 'kaiming', # xavier, xavier_uniform, kaiming, orthogonal\n","    'init_gain': 0.02,\n","    'generator_pretrained_checkpoint': '/path/to/pretrained_generator.pt',\n","    'rppgnet_pretrained_checkpoint': '/path/to/pretrained_rppgnet.pt',\n","    'gpu_ids': [0]\n","}\n","\n","opt = {\n","    'crop_size': 80,\n","    'batch_size': params['batch_size'],\n","}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dpBVi2HWVvu9"},"source":["# Create the save_path dir\n","if params['save_path']:\n","  Path(params['save_path']).mkdir(parents=True, exist_ok=True)\n","\n","# Dataloaders\n","root_dir = '/path/to/real_subjects' # Dir for the real subjects\n","root_dir_transfered = '/path/to/pseudo_gt' # Dir for the pseudo GT\n","\n","train_session_nums = [\n","    1, 3, 4, 5, 8, 9, 10, 11, 12, 13, 16, 17, 18, 20, \n","    23,  24, 25, 26, 27, 31, 32, 33, 35, 36, 38, 39, 40, \n","    41, 42, 45, 47, 49\n","    ]\n","\n","val_session_nums = [14, 15, 22, 30, 34, 37, 43, 44, 46, 48]\n","\n","# Check train and val overlap\n","for cur_session_num in val_session_nums:\n","  if cur_session_num in train_session_nums:\n","    print('Session overlap!', cur_session_num)\n","\n","train_session_names = []\n","for cur_session_num in train_session_nums:\n","  cur_session_name = 'subject' + str(cur_session_num) \n","  train_session_names.append(cur_session_name)\n","\n","val_session_names = []\n","for cur_session_num in val_session_nums:\n","  cur_session_name = 'subject' + str(cur_session_num) \n","  val_session_names.append(cur_session_name)\n","\n","# Device\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print('Device:', device)\n","\n","train_set = DatasetUBFC(\n","    root_dir=root_dir, \n","    root_dir_transfered=root_dir_transfered,\n","    session_names=train_session_names, \n","    num_samples=params['num_samples'],\n","    seq_length=params['seq_length'], \n","    device=device, \n","    resize_shape=params['img_shape'],\n","    )\n","ppg_train_loader = DataLoader(\n","    train_set,\n","    batch_size=params['batch_size'],\n","    shuffle=True,\n","    num_workers=0,\n","    pin_memory=True\n","    )\n","\n","val_set = DatasetUBFC(\n","    root_dir=root_dir, \n","    root_dir_transfered=root_dir_transfered,\n","    session_names=val_session_names, \n","    num_samples=params['num_samples'],\n","    seq_length=params['seq_length'], \n","    device=device, \n","    resize_shape=params['img_shape'],\n","    )\n","ppg_val_loader = DataLoader(\n","    val_set,\n","    batch_size=params['batch_size'],\n","    shuffle=True,\n","    num_workers=0,\n","    pin_memory=True\n","    )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2LRi3Y25la-e"},"source":["# Model\n","norm_layer = get_norm_layer3d(norm_type=params['norm'])\n","model = ResnetGenerator3d(params['input_nc'], params['output_nc'], params['ngf'], norm_layer=norm_layer, use_dropout=params['dropout'], n_blocks=6)\n","model = init_net(model, params['init_type'], params['init_gain'], params['gpu_ids'])\n","\n","if params['generator_pretrained_checkpoint']:\n","  print('Loading generator checkpoint:', params['generator_pretrained_checkpoint'])\n","  checkpoint = torch.load(params['generator_pretrained_checkpoint'])\n","  model.load_state_dict(checkpoint['model_state_dict'])\n","\n","model_rppgnet = RPPGNetResnet(params['seq_length'])\n","if params['rppgnet_pretrained_checkpoint']:\n","  print('Loading rppg checkpoint:', params['rppgnet_pretrained_checkpoint'])\n","  model_rppgnet.load_state_dict(torch.load(params['rppgnet_pretrained_checkpoint']))\n","model_rppgnet.to(device)\n","\n","# Reload optimizer \n","beta1 = params['beta1']\n","beta2 = params['beta2']\n","optimizer = optim.Adam(\n","    model.parameters(), lr=params['lr'], \n","    betas=(beta1, beta2), weight_decay=params['weight_decay']\n","    )\n","optimizer_rppgnet = optim.Adam(\n","    model_rppgnet.parameters(), lr=params['lr_rppgnet'], \n","    betas=(beta1, beta2), weight_decay=params['weight_decay']\n","    )\n","\n","# Scheduler\n","scheduler = optim.lr_scheduler.CosineAnnealingLR(\n","    optimizer, T_max=params['num_epochs'], eta_min=0, verbose=True\n","    )\n","\n","scheduler_rppgnet = optim.lr_scheduler.CosineAnnealingLR(\n","    optimizer_rppgnet, T_max=params['num_epochs'], eta_min=0, verbose=True\n","    )\n","\n","# Loss\n","criterion = ThresholdLoss()\n","criterion_rppg = NegPeaLoss()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Eb-LYMfJWUOa"},"source":["val_loss_history = []\n","train_loss_history = []\n","\n","for epoch in range(params['num_epochs']):\n","  print('\\nEpoch {}/{}'.format(epoch, params['num_epochs'] - 1))\n","  print('-' * 10)\n","\n","  # Training\n","  model.train()\n","  model_rppgnet.train()\n","\n","  running_g_loss = 0.0\n","  running_rppg_loss = 0.0\n","  running_rppg_loss_real = 0.0\n","  running_rppg_loss_fake = 0.0\n","\n","  # Iterate over data\n","  for i, data in enumerate(ppg_train_loader):\n","    next_ppg = data['next_ppg_value'].to(device) \n","    next_frame = data['next_frame'].to(device) \n","    next_frame_transfered = data['transfered_next_frame'].to(device)\n","    seq_length = next_ppg.shape[1]\n","    \n","    # Generator step\n","    optimizer.zero_grad()\n","   \n","    frame_transfered_hat = model(torch.transpose(next_frame, 1, 2))\n","    with torch.no_grad():\n","      est_ppg_hat = model_rppgnet(frame_transfered_hat)\n","    g_loss = params['rgb_loss_weight'] * criterion(\n","        torch.transpose(frame_transfered_hat, 1, 2), next_frame_transfered\n","    ) + params['rppgnet_loss_weight'] * criterion_rppg(est_ppg_hat.squeeze(), next_ppg)\n","    \n","    g_loss.backward()\n","    optimizer.step()\n","\n","    # rPPG step\n","    optimizer_rppgnet.zero_grad()\n","   \n","    est_ppg_transfered = model_rppgnet(frame_transfered_hat.detach())\n","    rppg_loss_fake = criterion_rppg(est_ppg_transfered.squeeze(), next_ppg)\n","    est_ppg_original = model_rppgnet(torch.transpose(next_frame, 1, 2))\n","    rppg_loss_real = criterion_rppg(est_ppg_original.squeeze(), next_ppg)\n","\n","    rppg_loss = rppg_loss_real + rppg_loss_fake\n","    rppg_loss.backward()\n","    optimizer_rppgnet.step()\n","\n","    running_g_loss += g_loss.item()\n","    running_rppg_loss += rppg_loss.item()\n","    running_rppg_loss_real += rppg_loss_real.item()\n","    running_rppg_loss_fake += rppg_loss_fake.item()\n","\n","    # Display some training frames\n","    if params['display_tensor'] and i == 0 and epoch % params['display_tensor'] == 0:\n","      \n","      # Pick a random frame\n","      idx = np.random.randint(0, next_frame.shape[0])\n","      multiple_tensors_show(\n","          [next_frame.detach().cpu()[idx][idx],\n","          next_frame_transfered.detach().cpu()[idx][idx],\n","          torch.transpose(frame_transfered_hat, 1, 2).detach().cpu()[idx][idx]],\n","          normalization_list=[False, False, False]\n","          )\n","\n","  epoch_g_loss = running_g_loss / len(ppg_train_loader)\n","  epoch_rppg_loss = running_rppg_loss / len(ppg_train_loader)\n","  epoch_rppg_loss_real = running_rppg_loss_real / len(ppg_train_loader)\n","  epoch_rppg_loss_fake = running_rppg_loss_fake / len(ppg_train_loader)\n","\n","  print('G Loss: {:.4f} '.format(epoch_g_loss))\n","  print('RPPGNet Loss: {:.4f} '.format(epoch_rppg_loss))\n","  print('RPPGNet Loss Real: {:.4f} '.format(epoch_rppg_loss_real))\n","  print('RPPGNet Loss Fake: {:.4f} '.format(epoch_rppg_loss_fake))\n","\n","  train_loss_history.append(epoch_g_loss)\n","\n","  # Adjust the scheduler\n","  scheduler.step()\n","  scheduler_rppgnet.step()\n","  \n","  # Validation \n","  if epoch % params['val_epoch'] == 0:\n","    model.eval()\n","    model_rppgnet.eval()\n","\n","    running_loss = 0.0\n","    running_loss_rppg = 0.0\n","    running_rppg_loss_real = 0.0\n","    running_rppg_loss_fake = 0.0\n","\n","    with torch.no_grad():\n","      # Iterate over data.\n","      for i, data in enumerate(ppg_val_loader):\n","        next_ppg = data['next_ppg_value'].to(device) \n","        next_frame = data['next_frame'].to(device) \n","        next_frame_transfered = data['transfered_next_frame'].to(device) \n","        seq_length = next_ppg.shape[1]\n","\n","        frame_transfered_hat = model(torch.transpose(next_frame, 1, 2))\n","\n","        loss = criterion(torch.transpose(frame_transfered_hat, 1, 2), next_frame_transfered)\n","        running_loss += loss.item()\n","       \n","        est_ppg_transfered = model_rppgnet(frame_transfered_hat)\n","        rppg_loss_fake = criterion_rppg(est_ppg_transfered.squeeze(), next_ppg)\n","        est_ppg_original = model_rppgnet(torch.transpose(next_frame, 1, 2))\n","        rppg_loss_real = criterion_rppg(est_ppg_original.squeeze(), next_ppg)\n","\n","        running_rppg_loss_real += rppg_loss_real.item()\n","        running_rppg_loss_fake += rppg_loss_fake.item()\n","        running_loss_rppg += rppg_loss_real.item() + rppg_loss_fake.item()\n","  \n","        # Display some frames\n","        if params['display_tensor'] and i == 0 and epoch % params['display_tensor'] == 0:\n","          # Pick a random frame\n","          idx = np.random.randint(0, next_frame.shape[0])\n","          multiple_tensors_show(\n","              [next_frame.detach().cpu()[idx][idx],\n","              next_frame_transfered.detach().cpu()[idx][idx],\n","              torch.transpose(frame_transfered_hat, 1, 2).detach().cpu()[idx][idx]],\n","              normalization_list=[False, False, False]\n","              )\n","    epoch_loss_rgb = running_loss / len(ppg_val_loader)\n","    epoch_loss_rppg = running_loss_rppg / len(ppg_val_loader)\n","    epoch_rppg_loss_real = running_rppg_loss_real / len(ppg_val_loader)\n","    epoch_rppg_loss_fake = running_rppg_loss_fake / len(ppg_val_loader)\n","\n","    print('Val Loss RGB: {:.4f} '.format(epoch_loss_rgb))\n","    print('Val Loss rPPG: {:.4f} '.format(epoch_loss_rppg))\n","    print('RPPGNet Loss Real: {:.4f} '.format(epoch_rppg_loss_real))\n","    print('RPPGNet Loss Fake: {:.4f} '.format(epoch_rppg_loss_fake))\n","    \n","    epoch_loss = epoch_rppg_loss_real\n","    val_loss_history.append(epoch_loss)\n","\n","    # Save the checkpoint after validation\n","    if params['save_path'] and epoch_loss <= min(val_loss_history):\n","      print('Saving in Epoch', epoch)\n","      torch.save({\n","          'epoch': epoch,\n","          'model_state_dict': model.state_dict(),\n","          'optimizer_state_dict': optimizer.state_dict(),\n","          'scheduler_state_dict': scheduler.state_dict(),\n","          'train_loss': train_loss_history,\n","          'val_loss': val_loss_history,\n","          }, os.path.join(params['save_path'], params['save_name_generator']))\n","      torch.save({\n","        'epoch': epoch,\n","        'model_state_dict': model_rppgnet.state_dict(),\n","        'optimizer_state_dict': optimizer_rppgnet.state_dict(),\n","        'scheduler_state_dict': scheduler_rppgnet.state_dict(),\n","        }, os.path.join(params['save_path'], params['save_name_rppgnet']))"],"execution_count":null,"outputs":[]}]}